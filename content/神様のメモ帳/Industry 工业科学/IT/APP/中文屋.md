---
tags:
  - Label/Industry-工业科学/IT/APP/Prototype/DAG
---

## 炼丹术
机器学习

[机器与人类视觉能力的差距（1）](http://www.yinwang.org/blog-cn/2019/09/14/machine-vs-human)

[机器与人类视觉能力的差距（2）](http://www.yinwang.org/blog-cn/2019/09/15/machine-vs-human-2)

[机器与人类视觉能力的差距（3）](http://www.yinwang.org/blog-cn/2019/09/16/machine-vs-human-3)

[卷积神经网络CNN完全指南终极版（一） - 知乎](https://zhuanlan.zhihu.com/p/27908027)

[卷积神经网络CNN完全指南终极版（二） - 知乎](https://zhuanlan.zhihu.com/p/28173972)

[都是假的---生成式对抗网络GAN完全指南终极版（一） - 知乎](https://zhuanlan.zhihu.com/p/28216012)

[重读Youtube深度学习推荐系统论文，字字珠玑，惊为神文 - 知乎](https://zhuanlan.zhihu.com/p/52169807)


    黑箱化严重


### 深度学习

深度学习能够衍生出自我吗？不能。

深度学习不过是「拟合游戏」罢了，更准确的说是「概率游戏」。里边没有半点和意识沾边的东西。

至于神经元之类的，没错，科技以起名为本

人工智能是个伪概念，什么乱七八糟的玩意都能叫人工智能。不建议在任何营销外的场合使用。

机器学习定义：大数据、算法、训练

深度学习定义：大数据、神经网络算法（分层）、训练。2006 年提出。分为 CNN、DBN 深度置信网。深度学习是机器学习的其中一个分支。

神经网络：深度学习使用的的算法。

卷积神经网络 CNN：主流的神经网络算法。CNN 可以说是深度学习最成功的应用算法。

机器学习和深度学习都从训练和测试模型开始，并经过优化找到一个权重使模型效果更好。两者都可以处理数字（回归）和非数字（分类）问题

深度学习与其他机器学习的主要区别是在于性能。当数据量很少的时候，深度学习的性能并不好，因为深度学习算法需要大量数据才能很好理解其中蕴含的模式。

所谓训练，大致可以理解为不断调整拟合函数的参数，使误差越来越小。

顺便说一下，深度学习完美契合泛函编程的规范，所以你总是看到一大堆递归套娃。




### 深度学习框架

随便了解了下，我比较喜欢 PyTorch、Keras，感觉比较适合我。

CUDA：
PyTorch：
Keras
Torch：
Horovod
TensorFlow
OpenCV
MegEngine
Paddle

时至今日，世界上主要的深度学习框架玩家都已露面，谷歌、脸书、亚马逊、百度、华为、旷视


### 行业

游戏币之后，又有新名词了，就叫它 **魔法行业（炼丹行业）** 吧。

本人中部985传统工科专业，毕设做的是深度学习故障诊断。翻译的论文是老师课题组发在applied energy的论文，刚开始觉得论文很牛逼，现在觉得那篇论文就是简单的用了DBN模型调调层数，学习率，迭代次数什么的，没有什么算法的改进，没想到SCI一区也可以这么灌水。。。写论文中也看了很多研究生论文，大多也是这样，套套算法，太水了。。

这真是一个神奇的行业。游戏币这种奇葩存在好歹是因为可以割韭菜，讲究的是愿者上钩。深度学习呢？既没有什么革命性的成果，原理欠缺、共识欠缺，现在连风投都骗不到，就这么实质上半死不活的现状，居然还有大把人趋之若鹜，倒是有点像围城，入圈的人迅速懵逼，发现圈里什么共识都没有，游戏币圈都要更真实。学什么都浮夸，仿佛空中楼阁，除了看似可以装逼什么用都没有。应用范围实际上也很狭窄，跟大众眼中的人工智能有些大方向上的本质区别，学完也不知道能干什么。就这样，业内人士还能维持自己的逼格，真是令人傻眼的行业

从这个角度，搞深度学习确实像炼丹师，因为除了一句性价比，你再也找不出理由解释模型的规模和结构为什么是这组数、这个结构。

可解释性（Interpretability）？别问，问就是魔法。一个只有 误差最小化 这一句实话与共识的行业，要什么解释

transformer 号称能找到最具性价比的魔法数字，但本身也是玄学，难以证伪

大数据并没有一个独立的学科体系，统计学，机器学习，数据挖掘，数据库，分布式计算，云计算，信息可视化等技术或方法都可以来对付数据。

如果说机器学习还能挤进学术圈，大数据就是学术圈都没有的纯工业应用。大数据的唯一原则就是大量数据，就如同深度学习的唯一原则是误差最小化。大数据是应用，至于应用的手段，怎样都行，机器学习、神经网络、统计学解释分析、数据可视化、后端数据库、分布式存储、分布式运算、运维、甚至是 PPT（数据挖掘），这些应用都可以叫大数据。

哪怕人工智能理解为机器学习或自动化，大数据也没资格成为一个专业。

另外提一嘴，大数据其实并不需要什么算力，对于企业来说，只要不跑深度学习，硬件与普通运维无异，顶多弄个分布式存储、分布式计算，这和换个操作系统没有本质区别。大数据大数据，给人的感觉好像是大量 CPU GPU 交火从数据中提取出情报，但实际上这种印象只属于深度学习，哦不，还有挖矿。事实是除了机器学习和挖矿，根本不需要高算力。大数据实质更接近运维，运维一堆只有企业才用的应用，Hadoop Spark……其实就是运维哩

至于所谓数据分析，就是统计学，新瓶装旧酒罢了

虽然我一直嘲讽炼丹行业，但这仅针对真正的人工智能角度。单从应用领域，我对炼丹领域抱有很高期望，它能直接给出很多问题的答案。例如，信任的进化，经典的答案真的正确吗？炼丹炉跑一跑就行。倘若得出了个更为复杂的方案，不就是对现有天花板的突破吗……就如同围棋一样，新时代定式越来越多淘汰改写旧定式，尽管人们一开始并不理解答案。从这个角度，「不可解释性」并非完全无法解释，而是「难以解释」，棋手们难以理解为什么这样的「无理手」能够成立。

所以我也将炼丹行业叫做魔法行业。不是弄明白了得出答案，而是先有答案而后才想办法弄明白。某种程度上，这也算是「时间机器」吧


### 规模

一句话，看效果。效果不够好，扩大规模，用大模型。效果足够好，精简规模，用小模型节省成本。最后一定会达到一个区间，区间内成本与效果之比最优，即最具性价比

数据集小，模型太大，最后出来的结果可能只比小模型好一点点，有时甚至更差，而且训练和推理速度都太慢了，最后就是为了1%的提升投入200%的算力，得不偿失。

数据集大，模型小，最后模型无法有效表征数据集，数据都浪费了，也不优。

最好是模型能跟着数据集等比例缩放，这个就太为难了，都是参数调优的工作，如何在深度和宽度上缩放模型，都出了几篇论文了。。。为什么是Resnet 101,50,34,18？都是魔法。现在出主干网络，都得附赠从大到小一整套的。

Transformer 就可以解决这个问题，这就是所谓的 scalability，面对一个数据集，出来一个恰恰好的网络，不大也不小。

### CV

其实所谓“神经网络”应该被叫做“可求导编程”。说穿了，所谓“神经网络”，“机器学习”，“深度学习”，就是利用微积分，梯度下降法，用大量数据拟合出一个函数，所以它只能做拟合函数能做的那些事情。

用了千万张图片和几个星期的计算，拟合出来的函数也不是那么可靠。人们已经发现用一些办法生成奇怪的图片，能让最先进的深度神经网络输出完全错误的结果。

神经网络为什么会有这种缺陷呢？因为它只是拟合了一个“像素=>名字”的函数。这函数碰巧能区分训练集里的图片，却不能抓住物体的结构和本质。它只是像素级别的拟合，所以这里面有很多空子可以钻。

深度神经网络经常因为一些像素，颜色，纹理匹配了物体的一部分，就认为图片上有这个物体。它无法像人类一样理解物体的结构和拓扑关系，所以才会被像素级别的肤浅假象所欺骗。

神经网络为什么会犯这种错误呢？因为它的目标只是把训练集里的图片正确分类，提高“识别率”。至于怎么分类，它可以是毫无原则的，它完全不理解物体的结构。它并没有看到“叶子”，“果皮”，“方盒子”，“按钮”，它看到的只是一堆像素纹理。因为训练集里面的图片，出现了类似纹理的都被标记为“菠萝蜜”和“遥控器”，没有出现这纹理的都被标记为其它物品。所以神经网络找到了区分它们的“分界点”，认为看到这样的纹理，就一定是菠萝蜜和遥控器。

我试图从神经网络的本质，从统计学来解释这个问题。神经网络其实是拟合一个函数，试图把标签不同的样本分开。拟合出来的函数试图接近一个“真实分界线”。所谓“真实分界线”，是一个完全不会错的函数，也就是“现实”。

数据量小的时候，函数特别粗糙。数据量大了，就逐渐逼近真实分界线。但不管数据量如何大，它都不可能得到完全准确的“解析解”，不可能正好抓住“现实”。

除非现实函数特别简单，运气特别好，否则用数据拟合出来的函数，都会有很多小“缝隙”。以上的像素攻击方法，就是找到真实分界线附近，“缝隙”里面的样本，它们正好让拟合函数出现分类错误。

人的视觉系统是完全不同的，人直接就看到了事物是什么，看到了“解析解”，看到了“现实”，而没有那个用数据逼近的过程，所以除非他累得头脑发麻或者喝了酒，你几乎不可能让他判断错误。

退一步来看，图像识别所谓的“正确分类”都是人定义的。是人给了那些东西名字，是许多人一起标注了训练用的图片。所以这里所谓的“解析解”，“现实”，全都是人定义的。一定是某人看到了某个事物，他理解了它的结构和性质，然后给了它一个名字。所以别的人也可以通过理解同一个事物的结构，来知道它是什么。

神经网络不能看到事物的结构，所以它们也就难以得到精确的分类，所以机器在图像识别方面是几乎不可能超越人类的。现在所谓的“超人类视觉”的深度学习模型，大部分都是欺骗和愚弄大众。使用没有普遍性的数据集，使用不公平的准确率标准来对比，所以才显得机器好像比人还厉害了。这是一个严重的问题，在后面我会详细分析。

深度学习训练出来的那些“参数”是不可解释的，因为它们存在的目的只是把数据拟合出来，把不同种类的图片分离开，而没有什么意义。AI 人士喜欢给这种“不可解释性”找借口，甚至有人说：“神经网络学到的数据虽然不可解释，但它却出人意料的有效。这些学习得到的模型参数，其实就是知识！”

这些模型真的那么有效吗？那为什么能够被如此离谱的图片所欺骗呢？说“那就是知识”，这说法简直荒谬至极，严重玷污了“知识”这个词的意义。这些“学习”得到的参数根本就不是本质的东西，不是知识，真的就是一堆毫无道理可言的数字，只为了降低“误差”，能够把特征空间的图片区分开来，所以神经网络才能被这样钻空子。

人为什么可以不受这种欺骗呢？因为人提取了高级的拓扑结构，不是瞎蒙的，所以人的判断不受像素的影响。因为提取了结构信息，人的观察是具有可解释性的。如果你问一个小孩，为什么你说这是一只猫而不是一只狗呢？她会告诉你：“因为它的耳朵是这样的，它的牙是那样的，它走路的姿势是那样的，它常常磨爪子，它用舌头舔自己……”

所以人的视觉系统很可能是跟深度神经网络原理完全不同的，或者只有最低级的部分有相似之处。

从这种研究的方式我们可以看出，即使是 MIT 这样高级的研究所，对视觉系统的研究还处于“猜”的阶段，把人脑作为黑盒子，拿一些图片来做“行为”级别的实验。他们并没有完全破解视觉系统，看到它的“线路”和“算法”具体如何工作，而是给它一些输入，测试它的输出。这就是“黑盒子”实验法。以至于很多关于人类视觉的理论都不是切实而确定的，很可能是错误的猜想。

脑科学发展到今天也还是如此，AI 领域相对于脑科学的研究方式，又要低一个级别。2019 年了，仍然抬出神经科学家 1959 年的结果来说事。闭门造车，对人家的最新成果一点都不关心。现在的深度神经网络模型基本是瞎蒙出来的。把一堆像素操作叠在一起，然后对大量数据进行“训练”，以为这样就能得到所有的视觉功能。

所以神经网络的各种做法恐怕没有受到 H&W 实验的多大启发。只是靠这么一个肤浅的相似之处来显得自己接近了“人类神经系统”。现在的所谓“神经网络”，其实只是一个普通的数学函数的表达式，里面唯一起作用的东西其实是微积分，所谓 back-propagation，就是微积分的求导操作。神经网络的“训练”，就是反复求导数，用梯度下降方法进行误差最小化，拟合一个函数。这一切都跟神经元的工作原理没什么关系，完全就是数学。

我发现每当主持人用稍微怀疑的语气问：“这真的可以实现吗？” Hinton 就会回答：“当然能。我们不都是神经网络吗？” 这里有一个严重的问题，那就是他所谓的“神经网络”，其实并不是人脑里面的神经元连成的网络。AI 领域的“神经网络”只是他们自己的数学模型，是他们自己给它起名叫“神经网络”而已。所以他的这种“证明”其实是在玩文字游戏：“因为我们都是神经网络，所以神经网络能够实现一切人类智能，感情，甚至意识本身！”

实际上生物学对生命体如何工作（how）的理解都还远远不够彻底，这就是为什么我们还有那么多病无法医治，甚至连一些小毛病都无法准确的根治，一直拖着，只是不会马上致命而已。“生命是什么”的 what 问题仍然是一个未解之谜，而不像 Hinton 说的，全都搞明白了，没什么特别的。

也许生命就是一种特别的东西呢？也许只有从有生命的事物，才能产生有生命的事物呢？也许生命就是从外星球来的，也许就是由某种更高级的智慧设计出来的呢？这些都是有可能的。真正的科学家应该保持开放的心态，不应该有类似“人定胜天”这样的信仰。我们的一切结论都应该有证据，如果没有我们就不应该说“一定”或者“必然”，说得好像所有秘密全都解开了一样。

对于智能和意识，我也是一样的态度。在我们没有从普通的物质制造出真正的智能和意识之前，不应该妄言理解了关于它们的一切。生命，智能和意识，比有些人想象的要奇妙得多。想要“人造”出这些东西，比 AI 人士的说法要困难许多。

有心人仔细观察一下身边的小孩子，小动物，甚至观察一下自己，就会发现它们的“设计”是如此的精巧，简直不像是随机进化出来的，而是由某个伟大的设计者创造的。46 亿年的时间，真的够进化和自然选择出这样聪明的事物吗？

别误会了，我是不信宗教的。我觉得宗教的圣经都是小人书，都是某些人吓编的。可是如果你坚定的相信人类和动物的这些精巧的结构都是“进化”来的，你坚定的相信它们不是什么更高级的智慧创造出来的，那不也是另外一种宗教吗？你没有证据。没有证据的东西都只是猜想，而不能坚信。

设计神经网络的“算法工程师”，“数据科学家”，他们工作性质其实很像“炼丹师”（alchemist）。拿个模型这改改那改改，拿海量的图片来训练，“准确率”提高了，就发 paper。至于为什么效果会好一些，其中揭示了什么原理，模型里的某个节点是用来达到什么效果的，如果没有它会不会其实也行？不知道，不理解。甚至很多 paper 里的结果无法被别的研究者复现，存在作假的可能性。

我很怀疑这样的研究方式能够带来什么质的突破，这不是科学的方法。如果你跟我一样，把神经网络看成是用“可求导编程语言”写出来的代码，那么现在这种设计模型的方法就很像“一百万只猴子敲键盘”，总有一只能敲出“Hello World！”

许多数学家和统计学家都不认同 AI 领域的研究方式，对里面的很多做法表示不解和怀疑。为此斯坦福大学的统计学系还专门开了一堂课 Stats 385，专门讨论这个问题。课堂上请来了一些老一辈的数学家，一起来分析深度学习模型里面的各种操作是用来达到什么目的。有一些操作很容易理解，可是另外一些没人知道是怎么回事，这些数学家都看不明白，连设计这些模型的炼丹师们自己都不明白。

如此衡量“准确率”，有点像你做个编译器，却只针对很小一个 benchmark 进行优化跑分。一旦遇到实际的代码，别人可能就发现性能不行。但神经网络训练需要的硬件等条件比较昂贵，一般人可能也很少有机会进行完整的模型训练和实际的测试，所以大家只有任凭业内人士说“超人类准确率”，却无法验证它的实际效果。

不但测试数据的“通用性”值得怀疑，所谓“准确率”的计算标准也来的蹊跷。AI 领域向公众宣扬神经网络准确率的时候，总喜欢暗地里使用所谓“top-5 准确率”，也就是说每张图片给 5 次机会分类，只要其中一个对了就算正确，然后计算准确率。依据 top-5 准确率，他们得出的结论是，某些神经网络模型识别图像的准确率已经“超越了人类”。

如果他们提到“top-5”还算好的了，大部分时候他们只说“准确率”，而不提“top-5”几个字。在跟人比较的时候，总是说“超越了人类”，而绝口不提“top-5”，不解释是按照什么标准。我为什么对 top-5 有如此强烈的异议呢？现在我来解释一下。

具体一点，“top-5”是什么意思呢？也就是说对于一张图片，你可以给出 5 个可能的分类，只要其中一个对了就算分类正确。比如图片上本来是汽车，我看到图片，说：

1. “那是苹果？”
2. “哦不对，是杯子？”
3. “还是不对，那是马？”
4. “还是不对，所以是手机？”
5. “居然还是不对，那我最后猜它是汽车！”

五次机会，我说出 5 个风马不及的词，其中一个对了，所以算我分类正确。荒谬吧？这样继续，给很多图片分类，然后统计你的“正确率”。

为什么要给 5 次机会呢？ImageNet 比赛（ILSVRC）对两种不同的比赛给出了两种不大一样的说法。一种说是为了让机器可以识别出图片上的多个物体，而不因为其中某个识别出的物体不是正确标签（ground truth）而被算作错误。另外一种说是为了避免输出意义相同的近义词，却不能完全匹配标签而被算作错误。

两个说法的理由不同，但数学定义基本是一样的。总之就是有五次机会，只要对了一个就算你对。

看似合理？然而这却是模糊而错误的标准。这使得神经网络可以给出像上面那样风马不及的 5 个标签（苹果，杯子，马，手机，汽车），其中前四个都不是图片上的物体，却仍然被判为正确。

你可能觉得我的例子太夸张了，但是准确率计算标准不应该含有这样的漏洞。只要标准有漏洞，肯定会有错误的情况会被放过。现在我们来看一个实际点的例子。

其实要解决图片上有多个物体的问题，或者输出是近义词的问题，都有更好的办法，而不会让错误的结果被算成正确的。每一个学过基础数据结构和算法的本科生都应该能想出更好的解决方案。比如你可以用一个近义词词典，只要输出的标签和“正确标签”是近义词就算正确。对于有多个物体的图片，你可以在标注时给它多个标签，算法给出的标签如果在这个“正确标签集合”里面就算正确。

但 ILSVRC 并没有采用这些解决方案，而是采用了 top-5。这么基础而重要的问题，AI 业界的解决方案如此幼稚，却被全世界研究者广泛接受。你们不觉得蹊跷吗？我觉得他们有自己的目的：top-5 使得神经网络的准确率显得很高，只有使用这个标准，神经网络才会看起来“超越了人类”。

Top-5 准确率总是比 top-1 高很多。高多少呢？比如 ResNet-152 的 top-1 错误率是 19.38%，而 top-5 错误率却只有 4.49%。Top-1 准确率只能算“勉强能用”，换成 top-5 之后，忽然就可以宣称“超越人类”了，因为据说人类的 top-5 错误率大概是 5.1%。

虽然 Tesla 和 Uber 是应该被谴责的，但这里面的视觉问题不只是这两家公司的问题，整个自动驾驶的领域都建立在虚浮的基础上。我们应该清楚地认识到，现有的所谓 AI 根本没有像人类一样的视觉理解能力，它们只是非常粗糙的图像识别，识别率还远远达不到人类的水平，所以根本就不可能实现自动驾驶。

什么 L1~L4 的自动驾驶分级，都是瞎扯。根本没法实现的东西，分了级又有什么用呢？只是拿给这些公司用来忽悠大家的口号，外加推脱责任的借口而已。出事故前拿来做宣传：“我们已经实现 L2 自动驾驶，目前在研究 L3 自动驾驶，成功之后我们向 L4 进军！” 出事故后拿来推脱责任：“我们只是 L2 自动驾驶，所以这次事故是理所当然，不可避免的！”

如果没有视觉理解，依赖于图像识别技术的“自动驾驶车”，是不可能在复杂的情况下做出正确操作，保障人们安全的。机器人等一系列技术，也只能停留在固定场景，精确定位的“工业机器人”阶段，而不能在复杂的自然环境中行动。

要实现真正的语言理解和视觉理解是非常困难的，可以说是毫无头绪。一代又一代的神经学家，认知科学家，哲学家，为了弄明白人类“认知”和“理解”到底是怎么回事，已经付出了许多的努力。可是直到现在，对于人类认知和理解的认识都不足以让机器具有真正的理解能力。

真正的 AI 其实没有起步，很多跟 AI 沾点边的人都忙着忽悠和布道，没人关心其中的本质，又何谈实现呢？除非真正有人关心到问题所在，去研究本质的问题，否则实现真的理解能力就只是空中楼阁。我只是提醒大家不要盲目乐观，不要被忽悠了。与其夸大其词，欺骗大众，说人工智能快要实现了，不如拿已有的识别技术来做一些有用的事情，诚实地面对这些严重的局限性。

我并不是一味否定识别技术，我只是反对把“识别”夸大为“理解”，把它等同于“智能”，进行不实宣传，用于超出它能力的领域。诚实地使用识别技术还是有用的，而且蛮有趣。我们可以用这些东西来做一些很有用的工具，辅助我们进行一些事情。从语音识别，语音合成，图片搜索，内容推荐，商业金融数据分析，反洗钱，公安侦查，医学图像分析，疾病预测，网络攻击监测，各种娱乐性质的 app…… 它确实可以给我们带来挺多好处，实现我们以前做不到的一些事情。

但不要忘记，识别技术不是真的智能，它没有理解能力，不能用在自动驾驶，自动客服，送外卖，保洁阿姨，厨师，发型师，运动员等需要真正“视觉理解”或者“语言理解”能力的领域，更不能期望它们取代教师，程序员，科学家等需要高级知识的工作。机器也没有感情和创造力，不能取代艺术家，作家，电影导演。所有跟你说机器也能有“感情”或者“创造力”的都是忽悠，就像现在的对话系统一样，只是让人以为它们有那些功能，而其实根本就没有。

你也许会发现，机器学习很适合用来做那些不直观，人看不透，或者看起来很累的领域，比如各种数据分析。实际上那些就是统计学一直以来想解决的问题。可是视觉这种人类和高等动物的日常功能，机器的确非常难以超越。如果机器学习领域放弃对“人类级别智能”的盲目追求，停止拿“超人类视觉”一类的幌子来愚弄大众，各种夸大，那么他们应该能在很多方向做出积极的贡献。




### 杂

【入门深度学习】
Part 1：从机器学习开始（两个月）。最好的入门教程，就是吴恩达讲授的 [Machine Learning | Coursera](https://www.coursera.org/learn/machine-learning)。吴恩达这套课程发布很久了，虽然有些地方稍微过时，但相信我，现在没有任何公开的课程，能比吴恩达讲得更好。
Part 2：涉足深度学习（1个月）。开始研究深度学习之前，最好重温一下大学数学 [exacity/deeplearningbook-chinese: Deep Learning Book Chinese Translation](https://github.com/exacity/deeplearningbook-chinese)。关于深度学习的在线资料有很多，自己找找就是了。
Part 3：深度学习上手练（两个月）。自下而上，做了再说。可以看看斯坦福大学的 CS231n、CS224n





深度学习方向包括很多，最主要的几大类为

计算机视觉(CV)
自然语言处理（NLP）
推荐系统
语音



（1）计算机视觉（CV）

计算机视觉的研究方向很多，人脸检测，人脸识别，人脸合成，图像识别，目标检测，图像分割，GAN，图像风格迁移，3D目标检测，三维重建，超分辨率·，等等十分多的方向。不仅如此除了图像一些领域外，还包括视频领域的处理等，视频压缩等

（2）自然语言处理（NLP）

自然语言处理的研究方向略少，主要针对的是文本信息，比如机器翻译，文本分类，文本摘要生成，情感分析，文本纠错等

（3）推荐系统

这个方向我个人了解不多，主要的使用用途用于进行个性化的样本推荐

（4）语音方向

语音方向是单独一个方向，用来研究如何用神经网络的办法来进行语音信号的处理，语音的整个领域比较小， 主要包括语音识别，语音音色转换等

2. 人工智能的岗位要求是什么？

其实博主本人就是一名985的硕士，经过多方的了解，现在人工智能的就业前景真的是不敢苟同，在几年前的时候，会使用tensorflow，pytorch，可以跑跑模型训练，基本就是一份高薪的工作，但是现在已经不行了，现在的入门要求基本上要比以前高的多，如果是算法岗位。一般来说一定要有顶会的论文，ICML,NIPS,CVPR,AAAI,ICJAI,ACL,这样的顶级会议的论文，基本才能十拿九稳，或者是具有博士学位，其实不难看出，人确实很多，尤其是大厂以及互联网巨头等级的公司，基本上都要顶级的会议论文。其实有的人说，这是顶会劝退，其实不然，互联网公司的岗位也确实有限，每年的毕业生都是接近1千万甚至更多，其中博士，硕士，海归都有，所以相对来说，看一看硬件的条件也是可以理解。

再来可以看看现在ICML,CVPR等顶级会议的投稿量，竞争越来越激烈了，其他的一些专业的也都在进行人工智能方向的转行，如果门槛还不抬高，满足的人太多了。

3.对于一名研究生来说，选什么方向比较合适呢？

首先我们要知道一个情况，高校做人工智能研究的目的是什么，当然是为了出论文，出科研成果。就会来说，每年也会有大量的公司研究院，在CV领域，商汤之类的公司一直都是排行榜前列，他们在这个平台之下来展示自己的业务和科研能力。我个人认为高校研究生的位置比较尴尬，深度学习需要很强大的算力，要有很多的数据，才能做出非常炫酷的效果。但是和公司的研究院来说，高校一般没有那么强大的算力，我记得自己曾经跑过一个模型，Facebook公司的一个模型，他的训练时间是“epoch300，8张Tesla

v100，跑6天，一次完整的迭代差不多是30min”，所以可以看出，像现在比较新的方向，视频理解，三维重建，这种计算量巨大的模型，真的不太适合读研研究，方向比较难，数据也是限制。前一段时间除了GPT-3模型，训练一次的花费可以自己搜索一下。
